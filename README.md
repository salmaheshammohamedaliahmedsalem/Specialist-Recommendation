
# Personalized Medical Pre-Consultation via AI

This repository presents a comparative study of two AI-driven systems for automating the pre-consultation process in medical triage: a fine-tuned Large Language Model (LLM) and a Knowledge Graph-based semantic retrieval system. The goal is to dynamically generate follow-up questions and recommend the most appropriate specialist using only patient dialogue input.

---

## ğŸ§  Project Overview

We designed and implemented two separate pipelines:

- **Fine-Tuned LLM (LLaMA 3.2-3B + LoRA)** trained on weakly labeled medical dialogues for dynamic generation of questions and predictions.
- **Knowledge Graph (Neo4j + BioBERT embeddings)** that retrieves questions and specialists from previously matched similar cases.

This project compares their accuracy, adaptability, interpretability, and usability in real-world medical pre-consultation settings.

---

## ğŸ“ Directory Structure

```
ğŸ“ llmtuning/               # Notebook for LoRA-based LLM fine-tuning (llmtuning.ipynb)
ğŸ“ truelabeling/            # Notebook for expert-guided labeling evaluation (truelabeling.ipynb)
ğŸ“ data/                    # Dialogue data and structured patient case information
ğŸ“ figures/                 # Architecture diagrams and comparative illustrations
ğŸ“ knowledge_graph/         # Neo4j setup, case embedding, and retrieval scripts (see KG.ipynb)
ğŸ“„ requirements.txt         # Python dependencies
ğŸ“„ README.md                # This file
```

---

## âš™ï¸ System Pipelines

### ğŸ”· 1. Fine-Tuned LLM Pipeline
- **Labeling:** Uses Snorkel for weak supervision with keyword, TF-IDF, and zero-shot heuristics.
- **Training:** Fine-tunes Metaâ€™s LLaMA 3.2-3B with LoRA adapters using Hugging Face Transformers.
- **Inference:** Takes patient dialogue as prompt, generates follow-up questions, and predicts a specialist.
- See: `llmtuning.ipynb`

### ğŸ”¶ 2. Knowledge Graph Pipeline
- Refer to: `KG.ipynb` for end-to-end pipeline and graph construction.
- **Data Storage:** Neo4j graph with nodes: Case, Symptom, Question, Specialist.
- **Semantic Search:** Sentence embeddings (BioBERT) match incoming symptoms to previous cases.
- **Dialogue Replay:** Follows historic dialogue path and adapts based on patient responses.
- See: `knowledge_graph/`

---

## ğŸ“Š Evaluation Methodology

Evaluation was done using LLaMA 3.2-3B-Instruct in an expert simulation setting:
- Prompted as a senior medical expert.
- Rated each modelâ€™s question quality (scale 1â€“10).
- Judged specialist predictions as "Correct" or "Incorrect".

### ğŸ§ª Results Summary

| Metric                             | Fine-Tuned LLM | Knowledge Graph |
|------------------------------------|----------------|-----------------|
| Specialist Accuracy                | 65%            | 70%             |
| Question Quality Score (1â€“10)      | 7.0            | 6.0             |

---

## ğŸ–¼ï¸ System Architecture

Refer to `/figures/system_architecture.png` for a comparative visual.

---

## ğŸ§ª Requirements

```bash
pip install -r requirements.txt
```

- Python 3.10+
- Transformers (Hugging Face)
- Neo4j + neo4j-driver
- SentenceTransformers
- Snorkel
- LoRA modules (PEFT)

---

## ğŸš€ Running the System

### Fine-Tuned LLM
```bash
# Inside llmtuning.ipynb:
# 1. Load dataset
# 2. Apply Snorkel labeling
# 3. Fine-tune with LoRA adapters
# 4. Inference using text-generation pipeline
```

### Knowledge Graph
```bash
# knowledge_graph/
# 1. Load Neo4j
# 2. Insert cases with embeddings
# 3. Run symptom matching queries
```

---

## âœï¸ Authors

- Salma Salem  
- Malak El Samman  
- Rovan Ehab  
- Mohamed Youssef Hafez  
- Khadija Nasser

Department of Artificial Intelligence, Nile University â€“ Egypt

---

## ğŸ“œ License

For academic and research purposes only. Contact authors for usage permissions.
